% !TEX root =  master.tex
\chapter{Durchführung}

\section{Anforderungserhebung}
\label{sec:anforderungserhebung}

Die Anforderungserhebung bildet den Ausgangspunkt der Entwicklung und folgt dem in Abschnitt~\ref{sec:phase1} definierten Phasenmodell. Ziel ist die systematische Transformation impliziter Nutzerbedürfnisse in explizite, implementierbare Anforderungen. Dabei kommen drei komplementäre Erhebungsmethoden zum Einsatz, deren Ergebnisse im Folgenden dargestellt werden.

\subsection{Methodische Grundlagen der Erhebung}
\label{sec:erhebungsmethodik}

Die Anforderungserhebung stützt sich auf eine methodische Triangulation, die unterschiedliche Perspektiven auf die Problemdomäne vereint. Tabelle~\ref{tab:anforderungsquellen} gibt einen Überblick über die eingesetzten Methoden und deren spezifischen Beitrag zum Anforderungskatalog.

\begin{table}[htbp]
\centering
\caption{Übersicht der Anforderungsquellen und deren Beitrag}
\label{tab:anforderungsquellen}
\begin{tabular}{p{3.5cm}p{5cm}p{5cm}}
\toprule
\textbf{Methode} & \textbf{Durchführung} & \textbf{Identifizierte Anforderungen} \\
\midrule
Empirische Datenerhebung & Technischer Spieltest mit systematischer Protokollierung & Quest-Tracking, Item-Datenbank, Material-Kalkulation, Workstation-Planung \\
\addlinespace
Stakeholder-Interviews & Strukturierte Gespräche mit Spielern verschiedener Erfahrungsstufen & Recycling-Kalkulator (nachträglich priorisiert) \\
\addlinespace
Comparative Analysis & Heuristische Evaluation etablierter Companion Apps & Kanban-Board, Flow-Chart- und weitere Visualisierungen \\
\bottomrule
\end{tabular}
\end{table}

Die empirische Datenerhebung während des Spieltests ermöglichte die Identifikation konkreter Pain Points aus der Nutzerperspektive. Dabei kristallisierten sich drei zentrale Problemfelder heraus, die bereits in Abschnitt~\ref{sec:problemstellung} beschrieben wurden: die mangelnde Übersicht über Quest-Abhängigkeiten, die Komplexität der Ressourcenplanung sowie fehlende Unterstützung bei der Squad-Koordination.

Die Stakeholder-Interviews ergänzten diese Erkenntnisse um Anforderungen, die durch reine Selbstbeobachtung nicht erfasst werden konnten. Insbesondere das Recycling-Feature wurde erst durch ein Interview mit einem erfahrenen Spieler als kritischer Bedarf identifiziert, wie in Abschnitt~\ref{sec:fallbeispiel-recycling} detailliert dargestellt wird.

Die Comparative Analysis etablierter Companion Apps lieferte Best Practices für \ac{UI}/\ac{UX}-Patterns bei der Darstellung komplexer Spielinformationen. Hieraus wurden insbesondere das Kanban-Board-Konzept für die Quest-Übersicht sowie die Flow-Chart-Visualisierung für Abhängigkeitsdarstellungen abgeleitet.

\subsection{Transformation in User Stories}
\label{sec:userstories}

Die identifizierten Nutzerbedürfnisse werden nach dem \ac{INVEST}-Schema in User Stories transformiert~\cite{wake2003invest}. Jede User Story folgt dem etablierten Format:

\begin{quote}
\textit{\glqq Als [Rolle] möchte ich [Funktion], um [Nutzen] zu erreichen.\grqq{}}
\end{quote}

Das \ac{INVEST}-Akronym definiert dabei die Qualitätskriterien für gut formulierte User Stories: \textbf{I}ndependent (unabhängig voneinander umsetzbar), \textbf{N}egotiable (verhandelbar im Scope), \textbf{V}aluable (Wertvoll für den Nutzer), \textbf{E}stimable (schätzbar im Aufwand), \textbf{S}mall (klein genug für eine Iteration) und \textbf{T}estable (durch Akzeptanzkriterien validierbar).

Exemplarisch werden im Folgenden drei User Stories aus unterschiedlichen Feature-Bereichen vorgestellt, die die Bandbreite der funktionalen Anforderungen repräsentieren.

\subsubsection{US-QM-01: Quest-Übersicht als Kanban-Board}

\textbf{Quelle:} Issue ARC-24 \quad \textbf{Phase:} P1-Visualization \quad \textbf{Priorität:} Must-Have

\begin{quote}
\textit{\glqq Als Spieler möchte ich alle Quests in einem Kanban-Board mit den Spalten \glqq All\grqq{}, \glqq Active\grqq{}, \glqq Locked\grqq{} und \glqq Completed\grqq{} sehen, um meinen aktuellen Fortschritt auf einen Blick zu erfassen.\grqq{}}
\end{quote}

Diese User Story adressiert den in der Problemstellung identifizierten Mangel an Übersichtlichkeit bei der Quest-Verwaltung. Das Kanban-Board-Pattern wurde aus der Comparative Analysis als bewährtes Konzept für die Statusvisualisierung übernommen und auf den Gaming-Kontext adaptiert.

\subsubsection{US-RC-02: Reverse-Engineering von Recycling-Pfaden}

\textbf{Quelle:} Stakeholder-Interview \quad \textbf{Phase:} P1-Visualization (repriorisiert) \quad \textbf{Priorität:} Must-Have

\begin{quote}
\textit{\glqq Als Spieler möchte ich für ein Zielmaterial alle möglichen Recycling-Pfade sehen, um zu verstehen, welche Items ich recyceln kann, um das benötigte Material zu erhalten.\grqq{}}
\end{quote}

Diese User Story entstand aus einem Stakeholder-Interview und wurde aufgrund ihres hohen Nutzwerts nachträglich in die erste Entwicklungsphase aufgenommen. Die Entstehungsgeschichte wird in Abschnitt~\ref{sec:fallbeispiel-recycling} als Fallbeispiel für adaptives Anforderungsmanagement dokumentiert.

\subsubsection{US-MC-01: Material-Aggregation für Planung}

\textbf{Quelle:} Issue ARC-34 \quad \textbf{Phase:} P1-Visualization \quad \textbf{Priorität:} Must-Have

\begin{quote}
\textit{\glqq Als Spieler möchte ich basierend auf ausgewählten Quests und Workstation-Upgrades die Gesamtmenge benötigter Materialien berechnen, um mein begrenztes Inventar optimal zu nutzen.\grqq{}}
\end{quote}

Diese User Story adressiert direkt das Problem der ineffizienten Ressourcenplanung. Die Aggregationsfunktion ermöglicht eine vorausschauende Planung, die im Spielkontext durch das begrenzte Inventar besonders relevant ist.

\subsection{Definition von Akzeptanzkriterien}
\label{sec:akzeptanzkriterien}

Jede User Story wird durch messbare Akzeptanzkriterien konkretisiert, die eine objektive Validierung der Implementierung ermöglichen. Die Kriterien folgen dem SMART-Schema, dessen Dimensionen in Abbildung~\ref{fig:smart-mindmap} visualisiert sind.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{./img/smart_kriterien_mindmap.png}
\caption{Dimensionen der SMART-Kriterien für Akzeptanzkriterien}
\label{fig:smart-mindmap}
\end{figure}

Die \ac{SMART}-Kriterien stellen sicher, dass Akzeptanzkriterien \textbf{S}pezifisch (eindeutig und abgegrenzt), \textbf{M}essbar (quantifizierbar), \textbf{A}chievable (technisch umsetzbar), \textbf{R}elevant (beitragend zum Nutzwert) und \textbf{T}ime-bound (zeitlich einordenbar) formuliert sind.

Exemplarisch zeigt Tabelle~\ref{tab:ac-qm-01} die Akzeptanzkriterien für die User Story US-QM-01 (Kanban-Board für Quest-Übersicht).

\begin{table}[htbp]
\centering
\caption{Akzeptanzkriterien für US-QM-01 (Quest-Kanban-Board)}
\label{tab:ac-qm-01}
\begin{tabular}{clp{4cm}l}
\toprule
\textbf{ID} & \textbf{Kriterium} & \textbf{Messbar} & \textbf{Zeitpunkt} \\
\midrule
AC-QM-01.1 & Alle Quests in drei Spalten kategorisiert & Spaltenanzahl = 4 & Bei Seitenladung \\
\addlinespace
AC-QM-01.2 & Echtzeit-Filterung nach Quest-Name & Latenz $<$ 100ms & Bei Tastatureingabe \\
\addlinespace
AC-QM-01.3 & Numerische Quest-Anzahl pro Spalte & Counter sichtbar & Permanent \\
\bottomrule
\end{tabular}
\end{table}

Die Akzeptanzkriterien definieren präzise Metriken (Spaltenanzahl, Latenz in Millisekunden) und den Zeitpunkt der Validierung (bei Seitenladung, bei Interaktion). Diese Präzision ermöglicht eine eindeutige Überprüfung im Rahmen der Testphase.

\subsection{Fallbeispiel: Adaptives Anforderungsmanagement}
\label{sec:fallbeispiel-recycling}

Das Recycling-Feature demonstriert exemplarisch die Anwendung agiler Prinzipien im Anforderungsmanagement. Es illustriert, wie durch kontinuierliche Stakeholder-Einbindung Features mit hohem Nutzwert identifiziert werden können, die durch reine Selbstbeobachtung nicht erkannt wurden.

\subsubsection{Ausgangssituation}

Das initiale Backlog, abgeleitet aus dem Spieltest und der Comparative Analysis, sah die Interaktiven Karten (Issue ARC-37) als nächstes Feature der Phase P1-Visualization vor. Diese Priorisierung basierte auf der Annahme, dass Kartenvisualisierungen einen hohen Nutzwert für die Squad-Koordination bieten würden.

\subsubsection{Identifikation durch Stakeholder-Interview}

Während eines strukturierten Interviews in der zweiten Entwicklungsiteration artikulierte ein erfahrener Arc Raiders-Spieler folgenden Pain Point:

\begin{quote}
\textit{\glqq Ich brauche immer ewig um die richtigen Gegenstände zum recyclen zu finden, da man bei jedem Gegenstand einzeln das Menü öffnen muss, um zu erfahren in welche Materialien er zerlegt werden kann.\grqq{}}
\end{quote}

Diese Aussage offenbarte ein fundamentales Problem der Ressourcenverwaltung, das im Spieltest nicht als solches erkannt wurde. Das fehlende Verständnis der Recycling-Mechaniken führt zu suboptimalen Entscheidungen und damit zu ineffizienter Nutzung des ohnehin begrenzten Inventarplatzes.

\subsubsection{Analyse und Entscheidungsfindung}

Die Bewertung des neu identifizierten Bedarfs erfolgte anhand von vier Kriterien, die in Tabelle~\ref{tab:repriorisierung} den ursprünglich geplanten Interaktiven Karten gegenübergestellt werden.

\begin{table}[htbp]
\centering
\caption{Entscheidungsmatrix zur Repriorisierung}
\label{tab:repriorisierung}
\begin{tabular}{lcc}
\toprule
\textbf{Kriterium} & \textbf{Recycling-Kalkulator} & \textbf{Interaktive Karten} \\
\midrule
Identifizierter Nutzerbedarf & Hoch (validiert durch Interview) & Mittel (Annahme) \\
Technische Komplexität & Mittel & Hoch (externe Kartendaten) \\
Geschätzte Entwicklungszeit & $\sim$40 Stunden & $\sim$60 Stunden \\
Wissenschaftlicher Mehrwert & Hoch (Graph-Algorithmen) & Mittel \\
\bottomrule
\end{tabular}
\end{table}

Der Recycling-Kalkulator überzeugte durch einen validierten Nutzerbedarf, geringere technische Komplexität und kürzere Entwicklungszeit. Zusätzlich bot die Implementierung von Graph-Algorithmen für das Reverse-Engineering der Recycling-Pfade einen höheren wissenschaftlichen Mehrwert im Kontext dieser Arbeit.

\subsubsection{Resultierende Repriorisierung}

Basierend auf dieser Analyse wurde der Recycling-Kalkulator über die Interaktiven Karten priorisiert. Diese Entscheidung folgt dem agilen Grundprinzip: \textit{\glqq Reagieren auf Veränderung ist wertvoller als das Befolgen eines Plans\grqq{}}~\cite{agilemanifesto2001}.

Das Recycling-Feature wurde in drei User Stories unterteilt:
\begin{itemize}
    \item \textbf{US-RC-01:} Recycling-Datenbank mit Effizienzberechnung
    \item \textbf{US-RC-02:} Reverse-Engineering von Recycling-Pfaden
    \item \textbf{US-RC-03:} Visualisierung der Recycling-Ketten als Graph
\end{itemize}

Die Implementierung erfolgte in der ersten Entwicklungsphase (P1-Visualization), während die Interaktiven Karten auf eine spätere Iteration verschoben wurden.

\subsubsection{Erkenntnisse für den Entwicklungsprozess}

Das Fallbeispiel verdeutlicht drei zentrale Aspekte agilen Anforderungsmanagements:

Erstens kann kontinuierliche Stakeholder-Einbindung Features mit hohem Nutzwert identifizieren, die durch isolierte Analyse nicht erkannt werden. Die Recycling-Problematik war während des eigenen Spieltests nicht als kritisch wahrgenommen worden, da sie erst bei fortgeschrittenem Spielfortschritt relevant wird.

Zweitens ermöglicht flexible Priorisierung die Reaktion auf neue Erkenntnisse, ohne den Gesamtplan zu gefährden. Die Verschiebung der Interaktiven Karten hatte keine negativen Auswirkungen auf das \ac{MVP}.

Drittens erhöht die Dokumentation der Entscheidungsgrundlage die Nachvollziehbarkeit im wissenschaftlichen Kontext. Die explizite Gegenüberstellung der Optionen legitimiert die Repriorisierung und macht den agilen Entscheidungsprozess transparent.

\subsection{Priorisierung nach MoSCoW}
\label{sec:moscow}

Die \ac{MoSCoW}-Methode ermöglicht eine systematische Kategorisierung der Anforderungen nach ihrer Relevanz für das \ac{MVP}~\cite{clegg1994case}. Die Priorisierung berücksichtigt sowohl den erwarteten Nutzwert als auch den geschätzten Implementierungsaufwand.

Abbildung~\ref{fig:moscow-quadrant} visualisiert die Einordnung der identifizierten Features in einem Quadranten-Diagramm mit den Achsen \glqq Nutzwert\grqq{} und \glqq Aufwand\grqq{}. Features im oberen linken Quadranten (hoher Wert, niedriger Aufwand) werden als Must-Have klassifiziert, während Features im unteren rechten Quadranten (niedriger Wert, hoher Aufwand) auf spätere Releases verschoben werden.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/moscow_quadrant.png}
\caption{MoSCoW-Priorisierung der Features nach Nutzwert und Aufwand}
\label{fig:moscow-quadrant}
\end{figure}

Tabelle~\ref{tab:moscow} fasst die resultierende Kategorisierung zusammen und begründet die Zuordnung der einzelnen Feature-Gruppen.

\begin{table}[htbp]
\centering
\caption{MoSCoW-Kategorisierung der Anforderungen}
\label{tab:moscow}
\begin{tabular}{lp{5.5cm}p{5.5cm}}
\toprule
\textbf{Kategorie} & \textbf{Features} & \textbf{Begründung} \\
\midrule
Must-Have & Quest-Kanban, Flow-Chart, Quest-Details, Item-Katalog, Workstation-Übersicht, Material-Calculator, Recycling & Adressieren die in Abschnitt~\ref{sec:problemstellung} definierten Kernprobleme; bilden funktionales \ac{MVP} \\
\addlinespace
Should-Have & Quest-Progress und -Details, Dashboard-Statistiken, Wishlist-Integration & Erhöhen den Nutzwert signifikant; Anwendung funktional auch ohne diese Features \\
\addlinespace
Could-Have & Squad-Features, Pathfinding-Algorithmen, OCR-basierter Screenshot-Import, Interaktive Karten & Hoher Aufwand; für spätere Releases nach Validierung des \ac{MVP} geplant \\
\addlinespace
Won't-Have & Creature-Datenbank & Zusatzfeatures mit geringerer Dringlichkeit\\
\bottomrule
\end{tabular}
\end{table}

Die Must-Have-Features bilden das \ac{MVP} und adressieren direkt die drei Kernprobleme aus der Problemstellung: Informationsasymmetrie bei Quests (Kanban, Flow-Chart, Details), ineffizientes Ressourcenmanagement (Material-Calculator, Recycling-Features) und fehlende Planungsgrundlage (Item-Katalog, Workstation-Übersicht).

Die Should-Have-Features erweitern die Kernfunktionalität um Komfortfunktionen wie die Persistierung des Spielerfortschritts und aggregierte Statistiken. Diese Features erhöhen den Nutzwert erheblich, sind jedoch für die grundlegende Funktionsfähigkeit der Anwendung nicht zwingend erforderlich.

Die Could-Have- und Won't-Have-Features wurden bewusst zurückgestellt, um den Fokus auf die Kernfunktionalität zu wahren. Insbesondere die Squad-Features und Pathfinding-Algorithmen erfordern erheblichen Entwicklungsaufwand und sind erst nach erfolgreicher Validierung des \ac{MVP} sinnvoll zu implementieren.

% \subsection{Zusammenfassung und Überleitung}
% \label{sec:anforderung-zusammenfassung}

% Die Anforderungserhebung hat durch methodische Triangulation einen umfassenden Anforderungskatalog generiert. Aus dem Spieltest, den Stakeholder-Interviews und der Comparative Analysis wurden insgesamt 16 User Stories in vier Feature-Bereichen abgeleitet:

% \begin{itemize}
%     \item \textbf{Quest-Management:} 4 User Stories (US-QM-01 bis US-QM-04)
%     \item \textbf{Item-Datenbank:} 2 User Stories (US-ID-01, US-ID-02)
%     \item \textbf{Ressourcen-Management:} 6 User Stories (US-WP-01/02, US-MC-01/02, US-RC-01 bis US-RC-03)
%     \item \textbf{Dashboard:} 2 User Stories (US-DB-01, US-DB-02)
% \end{itemize}

% Das Fallbeispiel des Recycling-Kalkulators demonstrierte die praktische Anwendung agiler Prinzipien: Ein durch Stakeholder-Interview identifiziertes Feature wurde aufgrund seines validierten Nutzwerts über ursprünglich geplante Features priorisiert.

% Die \ac{MoSCoW}-Priorisierung strukturiert die Anforderungen nach ihrer Relevanz für das \ac{MVP}. Sieben Features wurden als Must-Have klassifiziert und bilden die Grundlage für die in den folgenden Abschnitten beschriebene Architektur- und Implementierungsphase.

% Die definierten Akzeptanzkriterien nach dem \ac{SMART}-Schema ermöglichen eine objektive Validierung der Implementierung und bilden die Basis für die in Abschnitt~\ref{sec:testen} beschriebene Testphase.

\section{Technologieentscheidungen}
\label{sec:technologieentscheidungen}

Die Auswahl geeigneter Technologien bildet das Fundament für eine erfolgreiche Implementierung. Anstelle einer ad-hoc-Entscheidung wird ein systematischer Evaluationsansatz mittels \ac{MCDA} angewandt, der die Nachvollziehbarkeit und Objektivität der Technologiewahl gewährleistet. Dabei werden bewusst unterschiedliche Architekturansätze verglichen: von vollständig verwalteten \ac{PaaS}-Lösungen über klassische \ac{IaaS}-Infrastruktur bis hin zu Self-Hosting-Optionen.

\subsection{Methodisches Vorgehen: Multi-Criteria Decision Analysis}
\label{sec:mcda-methodik}

Die \ac{MCDA} ist ein strukturiertes Verfahren zur Entscheidungsfindung bei mehreren, teilweise konkurrierenden Kriterien~\cite{belton2002multiple}. Das Vorgehen umfasst vier Schritte:

\begin{enumerate}
    \item \textbf{Kriteriendefinition:} Identifikation relevanter Bewertungskriterien basierend auf den Projektanforderungen
    \item \textbf{Gewichtung:} Zuweisung von Gewichtungsfaktoren entsprechend der relativen Bedeutung (Summe = 100\%)
    \item \textbf{Bewertung:} Qualitative Einschätzung jeder Alternative pro Kriterium auf einer Skala von 1 (ungenügend) bis 5 (exzellent)
    \item \textbf{Aggregation:} Berechnung gewichteter Gesamtpunktzahlen zur Identifikation der optimalen Lösung
\end{enumerate}

\subsection{Frontend-Framework-Evaluation}
\label{sec:frontend-evaluation}

Die Wahl des Frontend-Frameworks bestimmt maßgeblich die Entwicklungseffizienz, Performance und Wartbarkeit der Anwendung. Die Evaluation vergleicht vier fundamental unterschiedliche Ansätze: ein Full-Stack-Framework mit Server-Side Rendering, eine klassische \ac{SPA}-Architektur, einen Multi-Page-Application-Ansatz mit minimaler JavaScript-Abhängigkeit sowie ein alternatives Ökosystem.

\subsubsection{Evaluierte Alternativen}

\textbf{Next.js 14 (App Router):} Full-Stack React-Framework mit Server-Side Rendering, Static Site Generation und dem App Router mit React Server Components. Optimiert für \ac{PaaS}-Deployment auf Vercel, aber auch self-hostbar~\cite{nextjsdocs2024}.

\textbf{Vite + React (SPA):} Klassische Single-Page-Application-Architektur mit modernem Build-Tool. Framework-agnostisch und auf beliebiger Infrastruktur deploybar – von einem einfachen nginx-Server bis zu \ac{CDN}-Hosting~\cite{vite2024}.

\textbf{Astro + React Islands:} Multi-Page-Application-Framework mit Island Architecture. Generiert primär statisches HTML und hydriert nur interaktive Komponenten (\glqq Islands\grqq{}). Minimaler JavaScript-Footprint bei voller React-Kompatibilität~\cite{astro2024}.

\textbf{Angular 17:} Googles opinioniertes Full-Stack-Framework mit eigenem Ökosystem. Bietet SSR via Angular Universal, strikte Architekturvorgaben und umfassende Enterprise-Features~\cite{angular2024}.

\subsubsection{Kriteriendefinition und Gewichtung}

Die Kriterien und deren Gewichtung ergeben sich aus den projektspezifischen Anforderungen:

\begin{itemize}
    \item \textbf{SSR/SEO-Fähigkeit (20\%):} Für eine öffentlich zugängliche Companion App ist Suchmaschinenoptimierung relevant, um organischen Traffic zu generieren.
    \item \textbf{Developer Experience (20\%):} Die Entwicklungseffizienz ist bei begrenzter Projektlaufzeit kritisch. Hierzu zählen Hot Module Replacement, Debugging-Tools und Dokumentationsqualität.
    \item \textbf{Ecosystem \& Bibliotheken (15\%):} Verfügbarkeit von Bibliotheken für Graph-Visualisierung (React Flow, D3.js) und Charting.
    \item \textbf{Performance (15\%):} Ladezeiten, Bundle-Größe und Runtime-Performance beeinflussen die User Experience direkt.
    \item \textbf{TypeScript-Integration (10\%):} Durchgängige Typsicherheit reduziert Fehler und verbessert die Wartbarkeit.
    \item \textbf{Hosting-Flexibilität (10\%):} Unabhängigkeit von spezifischen Hosting-Plattformen; Möglichkeit zum Self-Hosting.
    \item \textbf{Lernkurve (10\%):} Einarbeitungsaufwand bei vorhandenen JavaScript/TypeScript-Kenntnissen.
\end{itemize}

\subsubsection{Entscheidungsmatrix Frontend-Framework}

Tabelle~\ref{tab:mcda-frontend} zeigt die Bewertung der Alternativen.

\begin{table}[htbp]
\centering
\caption{MCDA-Entscheidungsmatrix: Frontend-Framework}
\label{tab:mcda-frontend}
\begin{tabular}{lc|cccc|c}
\toprule
\textbf{Kriterium} & \textbf{Gew.} & \textbf{Next.js} & \textbf{Vite+React} & \textbf{Astro} & \textbf{Angular} & \textbf{Max} \\
\midrule
SSR/SEO-Fähigkeit & 20\% & 5 & 2 & 5 & 4 & 5 \\
Developer Experience & 20\% & 5 & 5 & 4 & 3 & 5 \\
Ecosystem \& Bibliotheken & 15\% & 5 & 5 & 4 & 3 & 5 \\
Performance & 15\% & 4 & 4 & 5 & 3 & 5 \\
TypeScript-Integration & 10\% & 5 & 4 & 4 & 5 & 5 \\
Hosting-Flexibilität & 10\% & 3 & 5 & 5 & 4 & 5 \\
Lernkurve & 10\% & 4 & 5 & 4 & 2 & 5 \\
\midrule
\textbf{Gewichtete Summe} & & \textbf{4,50} & \textbf{4,05} & \textbf{4,35} & \textbf{3,30} & 5,00 \\
\textbf{Rang} & & \textbf{1} & 3 & 2 & 4 & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Begründung der Bewertungen}

\textbf{Next.js 14} erreicht die höchste Gesamtpunktzahl (4,50) und wird als Frontend-Framework ausgewählt. Die Stärken liegen in der exzellenten SSR-Unterstützung durch den App Router, dem umfangreichen React-Ökosystem mit direkter Unterstützung für React Flow und Recharts sowie der nahtlosen TypeScript-Integration. Die eingeschränkte Hosting-Flexibilität (Bewertung 3) reflektiert die Tatsache, dass Next.js zwar self-hostbar ist, jedoch ohne Vercel auf einige Optimierungen verzichtet werden muss.

\textbf{Astro} (4,35) erreicht den zweiten Rang und wäre eine valide Alternative. Die Island Architecture liefert exzellente Performance durch minimalen JavaScript-Footprint. Für eine datenintensive Companion App mit komplexen interaktiven Visualisierungen würde jedoch ein Großteil der Seite aus \glqq Islands\grqq{} bestehen, was den architektonischen Vorteil relativiert.

\textbf{Vite + React} (4,05) exzelliert bei Developer Experience und Hosting-Flexibilität – die resultierende SPA kann auf jedem statischen Webserver deployed werden. Die fehlende native SSR-Unterstützung ist jedoch für eine SEO-relevante Companion App ein signifikanter Nachteil, der zusätzliche Infrastruktur (z.B. Prerendering-Service) erfordern würde.

\textbf{Angular 17} (3,30) bietet ein vollständiges Enterprise-Framework mit strikten Architekturvorgaben. Die steile Lernkurve, das separate Ökosystem (keine direkte Nutzung von React-Bibliotheken) und die vergleichsweise schwergewichtige Runtime machen es für ein Einzelentwickler-Projekt weniger geeignet.

\subsection{Backend- und Datenbank-Evaluation}
\label{sec:backend-evaluation}

Die Backend-Architektur muss die Speicherung von Spieldaten, Benutzerfortschritt und perspektivisch User-Generated Content unterstützen. Die Evaluation vergleicht vier fundamental unterschiedliche Ansätze: eine \ac{BaaS}-Plattform, eine selbst gehostete Lösung auf einem \ac{VPS}, eine klassische \ac{IaaS}-Architektur auf AWS sowie eine containerisierte Self-Hosting-Lösung.

\subsubsection{Evaluierte Alternativen}

\textbf{Supabase :} Open-Source Plattform mit PostgreSQL als Fundament, Realtime-Subscriptions, Row Level Security und Edge Functions. Managed Hosting mit großzügigem Free Tier~\cite{supabase2024}.

\textbf{Self-Hosted PostgreSQL + Node.js API (VPS):} Klassische Drei-Schichten-Architektur auf einem Virtual Private Server (z.B. Hetzner, DigitalOcean). PostgreSQL-Datenbank, Express/Fastify-API und nginx als Reverse Proxy. Vollständige Kontrolle bei moderatem Administrationsaufwand.

\textbf{AWS (RDS + Lambda + API Gateway):} Enterprise-Grade \ac{IaaS}-Lösung mit managed PostgreSQL (RDS), serverless Compute (Lambda) und API Gateway. Hochskalierbar mit Pay-per-Use-Modell, jedoch komplexe Konfiguration und potenziell hohe Kosten.

\textbf{Self-Hosted mit Coolify/Dokku (PaaS-on-VPS):} Selbst gehostete \ac{PaaS}-Lösung auf eigenem Server. Coolify oder Dokku abstrahieren die Infrastruktur ähnlich wie Heroku, laufen aber auf eigener Hardware. Kombiniert Kontrolle mit reduziertem Ops-Aufwand.

\subsubsection{Kriteriendefinition und Gewichtung}

\begin{itemize}
    \item \textbf{Relationales Datenmodell (20\%):} Die komplexen Beziehungen zwischen Quests, Items, Workstations und deren Abhängigkeiten erfordern ein relationales Schema mit Foreign Keys und Joins.
    \item \textbf{Kosteneffizienz (20\%):} Als Hobby-Projekt ohne Monetarisierung ist ein niedriges Kostenmodell essentiell.
    \item \textbf{Administrationsaufwand (20\%):} Zeit für Setup, Wartung, Backups und Security-Updates reduziert die verfügbare Entwicklungszeit.
    \item \textbf{Realtime-Fähigkeit (10\%):} Für zukünftige Squad-Features ist Echtzeit-Synchronisation relevant.
    \item \textbf{TypeScript/ORM-Integration (10\%):} Kompatibilität mit Type-Safe ORMs wie Drizzle oder Prisma.
    \item \textbf{Skalierbarkeit (10\%):} Fähigkeit zur Bewältigung von Nutzerwachstum ohne Architekturänderung.
    \item \textbf{Kontrolle \& Flexibilität (10\%):} Anpassbarkeit, Zugriff auf Konfiguration, Unabhängigkeit von Anbieter-Entscheidungen.
\end{itemize}

\subsubsection{Entscheidungsmatrix Backend/Datenbank}

\begin{table}[htbp]
\centering
\caption{MCDA-Entscheidungsmatrix: Backend und Datenbank}
\label{tab:mcda-backend}
\begin{tabular}{lc|cccc|c}
\toprule
\textbf{Kriterium} & \textbf{Gew.} & \textbf{Supabase} & \textbf{VPS} & \textbf{AWS} & \textbf{Coolify} & \textbf{Max} \\
\midrule
Relationales Datenmodell & 20\% & 5 & 5 & 5 & 5 & 5 \\
Kosteneffizienz & 20\% & 5 & 4 & 2 & 4 & 5 \\
Administrationsaufwand & 20\% & 5 & 2 & 3 & 4 & 5 \\
Realtime-Fähigkeit & 10\% & 5 & 3 & 3 & 3 & 5 \\
TypeScript/ORM-Integration & 10\% & 5 & 5 & 4 & 5 & 5 \\
Skalierbarkeit & 10\% & 4 & 2 & 5 & 3 & 5 \\
Kontrolle \& Flexibilität & 10\% & 3 & 5 & 4 & 5 & 5 \\
\midrule
\textbf{Gewichtete Summe} & & \textbf{4,60} & \textbf{3,50} & \textbf{3,50} & \textbf{4,10} & 5,00 \\
\textbf{Rang} & & \textbf{1} & 3 & 3 & 2 & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Begründung der Bewertungen}

\textbf{Supabase} erreicht mit 4,60 die höchste Punktzahl und wird als Backend-Lösung ausgewählt. Die Kombination aus vollwertigem PostgreSQL, integrierter Realtime-Funktionalität und minimalem Administrationsaufwand ermöglicht die Fokussierung auf die Frontend-Entwicklung. Das großzügige Free Tier (500 MB Datenbank, 1 GB Dateispeicher, 50.000 monatliche API-Requests) deckt den Bedarf eines Hobby-Projekts ab. Die reduzierte Bewertung bei Kontrolle (3) reflektiert die Abhängigkeit von Supabase-spezifischen Features wie Row Level Security Policies.

\textbf{Coolify/Dokku} (4,10) erreicht den zweiten Rang und stellt eine attraktive Mittelweg-Lösung dar. Die selbst gehostete \ac{PaaS} auf einem günstigen VPS (ab ca. 5€/Monat bei Hetzner) kombiniert die Einfachheit eines managed Service mit voller Datenkontrolle. Der initiale Setup-Aufwand ist jedoch höher als bei Supabase.

\textbf{Self-Hosted VPS} (3,50) bietet maximale Kontrolle und Flexibilität, erfordert jedoch erheblichen Administrationsaufwand für PostgreSQL-Konfiguration, Backups, SSL-Zertifikate, Firewall-Regeln und Security-Updates. Für einen Einzelentwickler mit Fokus auf Frontend-Features ist dieser Overhead signifikant.

\textbf{AWS} (3,50) bietet Enterprise-Grade-Infrastruktur mit exzellenter Skalierbarkeit, jedoch zu Lasten der Kosteneffizienz und Komplexität. Selbst bei minimaler Nutzung entstehen Kosten für RDS, Lambda, API Gateway, CloudWatch und Netzwerk-Traffic. Die Lernkurve für die AWS-Konsole und \ac{IAM}-Konfiguration ist beträchtlich.

\subsection{Deployment-Plattform-Evaluation}
\label{sec:deployment-evaluation}

Die Deployment-Plattform muss eine reibungslose \ac{CI}/\ac{CD}-Integration, Preview Deployments für iterative Entwicklung und kosteneffizientes Hosting ermöglichen. Die Evaluation vergleicht eine spezialisierte \ac{PaaS}-Lösung, eine klassische \ac{IaaS}-Architektur auf AWS, ein Self-Hosting-Setup auf einem VPS sowie eine containerisierte Lösung.

\subsubsection{Evaluierte Alternativen}

\textbf{Vercel:} Framework-aware Deployment-Plattform mit nativer Next.js-Optimierung, Edge Functions, globalem \ac{CDN} und automatischen Preview Deployments. Spezialisiert auf Frontend-Frameworks~\cite{vercel2024}.

\textbf{AWS (S3 + CloudFront + EC2):} Klassische \ac{IaaS}-Architektur mit S3 für statische Assets, CloudFront als \ac{CDN}, EC2 für SSR-Funktionen und Route53 für DNS. Maximale Kontrolle bei hoher Komplexität.

\textbf{Self-Hosted VPS (nginx + PM2):} Traditionelles Deployment auf einem Virtual Private Server mit nginx als Reverse Proxy und PM2 als Node.js Process Manager. Günstig und vollständig kontrollierbar.

\textbf{Docker + Kubernetes (Self-Managed):} Container-basiertes Deployment mit Docker-Images und Kubernetes-Orchestrierung (z.B. k3s auf eigenem Server oder managed K8s). Maximale Portabilität und Skalierbarkeit.

\subsubsection{Kriteriendefinition und Gewichtung}

\begin{itemize}
    \item \textbf{Next.js-Kompatibilität (25\%):} Unterstützung für App Router, Server Components, \ac{ISR} und Edge Runtime.
    \item \textbf{Kosteneffizienz (25\%):} Gesamtkosten für Hosting eines Hobby-Projekts mit moderatem Traffic.
    \item \textbf{Administrationsaufwand (20\%):} Zeit für Setup, Wartung und Troubleshooting.
    \item \textbf{CI/CD \& Preview Deployments (15\%):} Automatisierte Builds und Branch-basierte Preview-Umgebungen.
    \item \textbf{Kontrolle \& Portabilität (15\%):} Unabhängigkeit von Plattform-Lock-In, Möglichkeit zur Migration.
\end{itemize}

\subsubsection{Entscheidungsmatrix Deployment}

\begin{table}[htbp]
\centering
\caption{MCDA-Entscheidungsmatrix: Deployment-Plattform}
\label{tab:mcda-deployment}
\begin{tabular}{lc|cccc|c}
\toprule
\textbf{Kriterium} & \textbf{Gew.} & \textbf{Vercel} & \textbf{AWS} & \textbf{VPS} & \textbf{K8s} & \textbf{Max} \\
\midrule
Next.js-Kompatibilität & 25\% & 5 & 3 & 3 & 4 & 5 \\
Kosteneffizienz & 25\% & 4 & 2 & 5 & 3 & 5 \\
Administrationsaufwand & 20\% & 5 & 2 & 2 & 1 & 5 \\
CI/CD \& Preview & 15\% & 5 & 3 & 2 & 4 & 5 \\
Kontrolle \& Portabilität & 15\% & 2 & 4 & 5 & 5 & 5 \\
\midrule
\textbf{Gewichtete Summe} & & \textbf{4,25} & \textbf{2,75} & \textbf{3,45} & \textbf{3,30} & 5,00 \\
\textbf{Rang} & & \textbf{1} & 4 & 2 & 3 & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Begründung der Bewertungen}

\textbf{Vercel} erreicht mit 4,25 die höchste Punktzahl und wird als Deployment-Plattform ausgewählt. Als Entwickler von Next.js bietet Vercel die beste Framework-Integration mit automatischer Erkennung und Optimierung aller Next.js-Features. Die Preview-Deployment-Funktionalität unterstützt den agilen Entwicklungsprozess durch automatische Deployments für jeden Pull Request. Die niedrige Bewertung bei Kontrolle (2) reflektiert das Vendor Lock-In: Eine Migration weg von Vercel würde den Verlust von Optimierungen wie Edge Functions und \ac{ISR} bedeuten.

\textbf{Self-Hosted VPS} (3,45) erreicht den zweiten Rang und wäre eine kosteneffiziente Alternative. Ein Hetzner Cloud Server (CX11, ca. 4€/Monat) kann eine Next.js-Anwendung mit moderatem Traffic problemlos hosten. Der manuelle Setup von nginx, SSL-Zertifikaten (Let's Encrypt), CI/CD (GitHub Actions + SSH Deploy) und Monitoring erfordert jedoch Initial- und Wartungsaufwand.

\textbf{Docker + Kubernetes} (3,30) bietet maximale Portabilität – das Docker-Image kann auf beliebiger Infrastruktur deployed werden. Für ein Einzelentwickler-Projekt ist der Overhead von Kubernetes (selbst k3s) jedoch unverhältnismäßig. Die Komplexität von Ingress-Konfiguration, Persistent Volumes und Cluster-Maintenance übersteigt den Nutzen.

\textbf{AWS} (2,75) bietet Enterprise-Grade-Features, jedoch mit erheblicher Komplexität und Kosten. Die manuelle Konfiguration von S3-Buckets, CloudFront-Distributions, EC2-Instanzen, Load Balancern und \ac{IAM}-Policies erfordert signifikantes AWS-Expertise. Für Next.js-SSR müssten zusätzlich Lambda@Edge oder EC2-Instanzen konfiguriert werden.

\subsection{Resultierender Technologie-Stack}
\label{sec:tech-stack-zusammenfassung}

Die MCDA-Evaluation identifiziert folgenden optimalen Technologie-Stack für die Arc Raiders Companion App:

\begin{table}[htbp]
\centering
\caption{Resultierender Technologie-Stack}
\label{tab:tech-stack}
\begin{tabular}{llcl}
\toprule
\textbf{Kategorie} & \textbf{Technologie} & \textbf{Score} & \textbf{Kernargument} \\
\midrule
Frontend-Framework & Next.js 14 (App Router) & 4,50 & SSR + React-Ecosystem \\
Backend/Datenbank & Supabase + PostgreSQL & 4,60 & Minimaler Ops-Aufwand + Realtime \\
Deployment & Vercel & 4,25 & Native Next.js-Optimierung \\
\midrule
ORM & Drizzle & -- & TypeScript-native, performant \\
State Management & Zustand & -- & Minimalistisch, localStorage-Sync \\
UI-Framework & Radix UI + Tailwind CSS & -- & Accessible + Utility-First \\
Visualisierung & React Flow + Recharts & -- & Graph-Visualisierung + Charts \\
\bottomrule
\end{tabular}
\end{table}

Die Entscheidung für den \glqq Managed Stack\grqq{} (Next.js + Supabase + Vercel) priorisiert Entwicklungseffizienz und minimalen Administrationsaufwand gegenüber maximaler Kontrolle. Diese Priorisierung ist projektspezifisch begründet: Als Einzelentwickler-Projekt mit begrenzter Laufzeit und Fokus auf Frontend-Features überwiegt der Nutzen reduzierter Infrastruktur-Komplexität die Nachteile des Vendor Lock-In.

Für Projekte mit anderen Rahmenbedingungen – etwa einem dedizierten DevOps-Team, höheren Anforderungen an Datensouveränität oder langfristiger Kostensensitivität – könnte Beispielsweise die Kombination aus \textbf{Astro + Self-Hosted PostgreSQL + VPS} eine valide Alternative darstellen.

\subsection{Kritische Würdigung der Methodik}
\label{sec:mcda-kritik}

Die angewandte MCDA-Methodik unterliegt inhärenten Limitierungen. Die Gewichtung der Kriterien erfolgt subjektiv und projektspezifisch; andere Projekte könnten bei abweichenden Anforderungen zu unterschiedlichen Ergebnissen gelangen. Insbesondere die hohe Gewichtung von \glqq Administrationsaufwand\grqq{} (20\% bei Backend, 20\% bei Deployment) reflektiert die Einzel\-entwickler-Situation und würde in einem Team-Kontext anders ausfallen.

Die qualitativen Bewertungen basieren auf der Evaluation zum Zeitpunkt der Entscheidungsfindung (Oktober 2025) und können sich durch Technologie-Updates ändern. Beispielsweise könnte eine zukünftige Verbesserung der Self-Hosting-Dokumentation von Next.js die Hosting-Flexibilität-Bewertung erhöhen.

Dennoch bietet die strukturierte Evaluation gegenüber einer Ad-hoc-Entscheidung mehrere Vorteile: Die explizite Kriteriendefinition zwingt zur Reflexion der tatsächlichen Anforderungen, die dokumentierte Bewertung ermöglicht Nachvollziehbarkeit, und die Gegenüberstellung unterschiedlicher Architekturansätze (Managed vs. Self-Hosted vs. IaaS) macht Trade-offs explizit.

\section{Systemarchitektur und -design}
\label{sec:systemarchitektur}

Dieses Kapitel beschreibt die Architektur der Arc Raiders Companion App aus verschiedenen Perspektiven. Ausgehend von einer Kontextabgrenzung auf Systemebene wird das Datenbankdesign erläutert, bevor die Komponentenarchitektur und der Datenfluss am Beispiel des Quest-Management-Systems detailliert werden.

\subsection{Systemkontext und externe Schnittstellen}
\label{sec:systemkontext}

Das Kontextdiagramm in Abbildung~\ref{fig:context-diagram} visualisiert die Systemgrenzen der ArcDéx-Anwendung sowie deren Interaktion mit externen Akteuren und Diensten. Die Darstellung folgt dem arc42-Template, das eine standardisierte Dokumentation von Softwarearchitekturen ermöglicht~\cite{arc42}.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{./img/context_diagram.png}
\caption{Kontextdiagramm der ArcDéx Companion App}
\label{fig:context-diagram}
\end{figure}

\subsubsection{Externe Akteure und Systeme}

\textbf{Player (Primärer Akteur):} Der Spieler interagiert über einen Webbrowser via HTTPS mit der Anwendung. Die Kommunikation erfolgt über das globale \ac{CDN} von Vercel, das statische Assets cached und dynamische Anfragen an Serverless Functions weiterleitet.

\textbf{Vercel (Hosting-Infrastruktur):} Die Next.js-Anwendung wird auf Vercels Edge-Netzwerk gehostet. Vercel übernimmt das automatische Deployment, SSL-Terminierung, \ac{CDN}-Distribution und die Ausführung von Serverless Functions für \ac{SSR} und Server Actions.

\textbf{Supabase (Backend-as-a-Service):} Die PostgreSQL-Datenbank wird von Supabase gehostet und verwaltet. Die Kommunikation erfolgt über Drizzle \ac{ORM}, das type-safe Datenbankabfragen in TypeScript ermöglicht. Supabase stellt zusätzlich Realtime-Subscriptions für zukünftige Squad-Features bereit.

\textbf{Clerk (Authentication Provider):} Die Benutzerauthentifizierung wird an Clerk ausgelagert, einen spezialisierten Auth-Provider mit OAuth-Integration. Dies externalisiert die sicherheitskritische Authentifizierungslogik und ermöglicht Social Login via Discord, Google und anderen Providern.

\textbf{Game Data (Datenquelle):} Die Spieldaten von Arc Raiders werden über einen automatisierten Pipeline-Prozess synchronisiert. Eine GitHub Action triggert periodisch eine Supabase Edge Function, die aktualisierte Spieldaten aus der Community-Datenquelle importiert und in die PostgreSQL-Datenbank schreibt.

\subsubsection{Architektonische Entscheidungen auf Kontextebene}

Die Architektur folgt dem \glqq Managed Stack\grqq{}-Ansatz, der in Abschnitt~\ref{sec:technologieentscheidungen} evaluiert wurde. Die Externalisierung von Authentifizierung (Clerk), Datenhaltung (Supabase) und Hosting (Vercel) reduziert den operativen Overhead und ermöglicht die Fokussierung auf die Anwendungslogik.

Die lose Kopplung zwischen den externen Diensten wird durch standardisierte Schnittstellen erreicht: OAuth 2.0 für Authentifizierung, REST/PostgreSQL-Protokoll für Datenbankzugriffe und HTTPS für alle Client-Server-Kommunikation.

\subsection{Datenbankdesign}
\label{sec:datenbankdesign}

Das relationale Datenbankschema bildet die Domänenobjekte des Spiels Arc Raiders ab und unterstützt die in Abschnitt~\ref{sec:anforderungserhebung} definierten funktionalen Anforderungen. Abbildung~\ref{fig:er-diagram} zeigt das \ac{ER}-Diagramm der PostgreSQL-Datenbank.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{img/er_diagram_light_legend.png}
\caption{Entity-Relationship-Diagramm der ArcDéx-Datenbank}
\label{fig:er-diagram}
\end{figure}

\subsubsection{Domänenmodell und Entitäten}

Das Schema gliedert sich in vier funktionale Bereiche, die den Feature-Bereichen der Anwendung entsprechen:

\textbf{Quest-Management:} Die Entität \texttt{quests} speichert die Grunddaten einer Quest (Name, Händler, Ziele, Erfahrungspunkte). Quest-Abhängigkeiten werden über die Assoziationstabelle \texttt{quest\_chain} als gerichteter Graph modelliert, wobei \texttt{previous\_quest\_id} auf die Voraussetzungs-Quest verweist. Die Tabellen \texttt{quest\_requirements} und \texttt{quest\_rewards} verknüpfen Quests mit den benötigten bzw. erhaltenen Items.

\textbf{Item-Datenbank:} Die zentrale Entität \texttt{items} enthält alle Spielgegenstände mit Attributen wie Typ, Seltenheit, Wert und Gewicht. Komplexe, variable Datenstrukturen wie Effekte (\texttt{effects}) werden als \texttt{JSONB}-Spalten gespeichert, was flexible Schemata innerhalb des relationalen Modells ermöglicht.

\textbf{Hideout-System:} Das Workstation-Upgrade-System wird durch drei Tabellen abgebildet: \texttt{hideout\_modules} definiert die verfügbaren Workstations mit maximalem Level, \texttt{hideout\_levels} spezifiziert die einzelnen Upgrade-Stufen mit sonstigen Voraussetzungen, und \texttt{hideout\_requirements} verknüpft jedes Level mit den benötigten Items.

\textbf{Skill-System:} Die Entität \texttt{skill\_nodes} repräsentiert die Fähigkeiten im Skill-Baum mit Attributen wie Kategorie, maximale Punkte und Position im Baum. Die Tabelle \texttt{skill\_prerequisites} modelliert die Abhängigkeiten zwischen Skills als gerichteten azyklischen Graphen.

\subsubsection{Mehrsprachigkeit durch JSONB}

Ein zentrales Designmerkmal ist die Unterstützung von Mehrsprachigkeit ohne zusätzliche Übersetzungstabellen. Textfelder wie \texttt{name} und \texttt{description} werden als \texttt{JSONB}-Objekte gespeichert:

\begin{lstlisting}[language=SQL, caption={Mehrsprachige Textspeicherung in JSONB}]
{
  "de": "Kameraobjektiv",
  "en": "Camera Lens",
  "hr": "Objektiv Kamere",
  "it": "Obiettivo fotografico",
}
\end{lstlisting}

Dieser Ansatz ermöglicht die dynamische Erweiterung um zusätzliche Sprachen ohne Schemaänderung und effiziente Abfragen über PostgreSQLs native JSONB-Operatoren. Die Anwendung extrahiert zur Laufzeit den Text für die aktuelle Benutzersprache.

\subsubsection{Graph-Strukturen für Abhängigkeiten}

Sowohl Quest-Ketten (\texttt{quest\_chain}) als auch Skill-Voraussetzungen (\texttt{skill\_prerequisites}) werden als Adjazenzlisten modelliert. Diese Struktur ermöglicht:

\begin{itemize}
    \item Effiziente Abfragen direkter Vorgänger/Nachfolger via Foreign Key Join
    \item Rekursive Pfadberechnung mit PostgreSQLs \texttt{WITH RECURSIVE} \ac{CTE}
    \item Zykluserkennung zur Sicherstellung der Datenintegrität
\end{itemize}

Die Wahl der Adjazenzliste gegenüber alternativen Ansätzen (Nested Sets, Materialized Paths) basiert auf dem Anwendungsprofil: Die Graphen sind relativ flach (typisch 3--5 Ebenen), Schreiboperationen sind selten (nur bei Datenimport), und die primären Lesezugriffe benötigen direkte Nachbarn, nicht vollständige Teilbäume.

\subsection{Komponentenarchitektur}
\label{sec:komponentenarchitektur}

Die Komponentenarchitektur folgt dem Schichtenmodell moderner React-Anwendungen mit klarer Trennung von Präsentation, Zustandsverwaltung und Datenzugriff. Abbildung~\ref{fig:component-diagram} illustriert die Architektur am Beispiel der Quest-Seite.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{img/quest_page_component_diagram.png}
\caption{Komponentendiagramm der Quest-Seite}
\label{fig:component-diagram}
\end{figure}

\subsubsection{UI Layer}

Die \texttt{QuestsPage}-Komponente fungiert als Orchestrator und koordiniert die untergeordneten View-Komponenten. Sie ist verantwortlich für das Layout, die Initialisierung des Datenabrufs und die Weiterleitung von Benutzerinteraktionen an die State-Schicht.

\subsubsection{View Components}

Drei spezialisierte View-Komponenten realisieren die unterschiedlichen Darstellungsformen der Quest-Daten:

\textbf{QuestCard:} Kartenbasierte Darstellung einer einzelnen Quest mit Status-Indikator, Händler-Badge und Kurzinformationen. Die Komponente liest den Completion-Status aus dem GameStore und visualisiert ihn durch Farbcodierung.

\textbf{QuestFlowChart:} Interaktive Graph-Visualisierung der Quest-Abhängigkeiten basierend auf React Flow. Die Komponente transformiert die Quest-Chain-Daten in Nodes und Edges und wendet den Dagre-Layout-Algorithmus für automatische Positionierung an. Jede Quest wird durch eine \texttt{QuestNode}-Komponente gerendert.

\textbf{QuestDetailModal:} Modale Detailansicht mit vollständigen Quest-Informationen, Requirements, Rewards und Navigation zu verknüpften Quests. Die Komponente ermöglicht das Markieren einer Quest als abgeschlossen.

\subsubsection{State Layer}

Die Zustandsverwaltung implementiert die in Abschnitt~\ref{sec:state-management-grundlagen} beschriebene Client-Server-State-Dichotomie:

\textbf{GameStore (Zustand):} Verwaltet den Client State, insbesondere die vom Benutzer markierten abgeschlossenen Quests (\texttt{completedQuests}). Der Store persistiert seine Daten automatisch im \texttt{localStorage} des Browsers, sodass der Fortschritt über Sessions hinweg erhalten bleibt.

\textbf{React Query Cache:} Verwaltet den Server State, d.h. die von der Datenbank geladenen Quest-Daten. Der Cache implementiert Stale-While-Revalidate-Semantik: Gecachte Daten werden sofort angezeigt, während im Hintergrund eine Aktualisierung geprüft wird.

\subsubsection{Data Layer}

\textbf{QuestQueries (Server Actions):} Next.js Server Actions kapseln die Datenbankabfragen und werden auf dem Server ausgeführt. Sie nutzen Drizzle \ac{ORM} für type-safe Queries und geben typisierte Ergebnisse an den Client zurück. Die Server Actions sind nicht direkt von Client-Komponenten aufrufbar, sondern werden über React Query orchestriert.

\textbf{Supabase (PostgreSQL):} Die Datenbank liefert die persistenten Daten. Der Zugriff erfolgt ausschließlich über die Server Actions, nie direkt vom Client, was die Sicherheit durch Kapselung gewährleistet.

\subsection{Datenfluss und State Management}
\label{sec:datenfluss}

Der Datenfluss in der Anwendung folgt einem unidirektionalen Muster, das die Nachvollziehbarkeit von Zustandsänderungen gewährleistet. Abbildung~\ref{fig:data-flow} zeigt den vereinfachten Datenfluss zwischen Client, Edge und Datenbank.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{img/simple_data_flow_diagram.png}
\caption{Vereinfachtes Datenflussdiagramm}
\label{fig:data-flow}
\end{figure}

\subsubsection{Client-seitiger Datenfluss}

React-Komponenten interagieren mit zwei Datenquellen: dem Zustand Store für lokale Benutzerdaten und dem Query Cache für Serverdaten. Die Komponenten sind \glqq dumme\grqq{} Präsentationskomponenten, die ihren Zustand nicht selbst verwalten, sondern aus den Stores beziehen. Zustandsänderungen erfolgen ausschließlich über definierte Actions, was das Debugging durch zentrale Logging-Punkte vereinfacht.

\subsubsection{Server-seitiger Datenfluss}

Datenbankabfragen werden durch React Query initiiert, das Server Actions auf Vercels Edge-Infrastruktur aufruft. Die Server Actions nutzen Drizzle \ac{ORM} für typsichere Queries gegen die Supabase-PostgreSQL-Datenbank. Die Ergebnisse werden serialisiert, an den Client übertragen und im Query Cache gespeichert.

\subsubsection{State-Derivation am Beispiel Quest-Status}

Abbildung~\ref{fig:state-flow} illustriert, wie der Quest-Status aus der Kombination von Server State (Quest-Daten) und Client State (Completion-Markierungen) abgeleitet wird.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{img/quest_page_state_diagram.png}
\caption{State-Flow-Diagramm der Quest-Seite}
\label{fig:state-flow}
\end{figure}

Der Quest-Status (\texttt{active}, \texttt{locked}, \texttt{completed}) ist ein abgeleiteter Zustand (Derived State), der aus zwei Quellen berechnet wird:

\begin{enumerate}
    \item \textbf{Quest-Daten (React Query):} Enthält die Quest-Chain-Informationen, d.h. welche Quests Voraussetzung für andere sind.
    \item \textbf{Completed Quests (Zustand Store):} Enthält die IDs der vom Benutzer als abgeschlossen markierten Quests.
\end{enumerate}

Die Statusberechnung erfolgt bei jedem Render durch eine Selektorfunktion:

\begin{lstlisting}[caption={Quest-Status-Berechnung als Derived State}]
const getQuestStatus = (quest, completedQuests, questChain) => {
  if (completedQuests.includes(quest.id)) return 'completed';
  
  const prerequisites = questChain
    .filter(chain => chain.questId === quest.id)
    .map(chain => chain.previousQuestId);
  
  const allPrerequisitesMet = prerequisites
    .every(preId => completedQuests.includes(preId));
  
  return allPrerequisitesMet ? 'active' : 'locked';
};
\end{lstlisting}

Dieser Ansatz vermeidet redundante Datenhaltung: Der Status wird nicht gespeichert, sondern zur Laufzeit berechnet. Änderungen am \texttt{completedQuests}-Array propagieren automatisch zu allen abhängigen Komponenten durch Reacts Reaktivitätssystem.

\subsection{Zusammenfassung der Architekturentscheidungen}
\label{sec:architektur-zusammenfassung}

Die Systemarchitektur der ArcDéx Companion App basiert auf folgenden zentralen Entscheidungen:

\begin{table}[htbp]
\centering
\caption{Zusammenfassung der Architekturentscheidungen}
\label{tab:architektur-entscheidungen}
\begin{tabular}{lp{5cm}p{5.5cm}}
\toprule
\textbf{Aspekt} & \textbf{Entscheidung} & \textbf{Begründung} \\
\midrule
Systemgrenzen & Managed Services für Auth, DB, Hosting & Reduzierter Ops-Aufwand für Einzelentwickler \\
\addlinespace
Datenmodell & Relationales Schema mit JSONB für flexible Strukturen & Starke Konsistenz + Flexibilität für Mehrsprachigkeit \\
\addlinespace
Graph-Strukturen & Adjazenzlisten für Quest-Chains und Skill-Trees & Optimiert für flache Graphen mit seltenen Schreiboperationen \\
\addlinespace
State Management & Client/Server-State-Trennung (Zustand + React Query) & Klare Verantwortlichkeiten, optimierte Caching-Strategien \\
\addlinespace
Derived State & Berechnung zur Laufzeit statt Speicherung & Vermeidung von Inkonsistenzen, Single Source of Truth \\
\bottomrule
\end{tabular}
\end{table}

Die Architektur priorisiert Wartbarkeit und Entwicklungseffizienz über maximale Performance. Für eine Companion App mit primär lesenden Zugriffen und moderatem Traffic ist dieser Trade-off angemessen. Bei signifikantem Nutzerwachstum könnten Optimierungen wie Denormalisierung häufig abgefragter Daten oder serverseitige Status-Berechnung evaluiert werden.

\section{Evaluation und Testdurchführung}
\label{sec:evaluation}

Dieses Kapitel beschreibt die Durchführung der Evaluationsphase gemäß dem in Abschnitt~\ref{sec:entwicklungsmethodik} definierten Phasenmodell. Die Phase 4 gliedert sich in eine quantitative Evaluation der funktionalen Anforderungen und Performance-Metriken sowie eine qualitative Evaluation der User Experience. Die Ergebnisse dieser Evaluation werden in Kapitel~\ref{chap:ergebnisse} präsentiert und diskutiert.

\subsection{Quantitative Evaluation}
\label{sec:quant-eval-durchfuehrung}

Die quantitative Evaluation verfolgt zwei Ziele: die Validierung der in Abschnitt~\ref{sec:akzeptanzkriterien} definierten Akzeptanzkriterien sowie die Messung von Performance-Metriken unter realistischen Bedingungen.

\subsubsection{Methodische Differenzierung der Testansätze}

Nicht alle Akzeptanzkriterien erfordern automatisierte Tests. Die Evaluation unterscheidet daher zwischen zwei Kategorien:

\textbf{Automatisierte E2E-Tests} werden für Akzeptanzkriterien mit expliziten Performance-Vorgaben eingesetzt. Diese Kriterien enthalten messbare Zeitangaben (z.B. \glqq Latenz < 100ms\grqq{}) oder quantifizierbare Schwellwerte, deren Einhaltung nur durch instrumentierte Tests objektiv nachweisbar ist. Tabelle~\ref{tab:e2e-test-scope} zeigt die für automatisierte Tests selektierten Kriterien.

\begin{table}[htbp]
\centering
\caption{Akzeptanzkriterien mit automatisierten E2E-Tests}
\label{tab:e2e-test-scope}
\begin{tabular}{llp{5cm}}
\toprule
\textbf{ID} & \textbf{Metrik} & \textbf{Zielwert} \\
\midrule
AC-QM-01.2 & Swimlane-Toggle-Reaktionszeit & < 200ms \\
AC-QM-01.3 & Filter-Latenz bei Texteingabe & < 100ms \\
AC-QM-02.3 & Flow-Chart-Render-Zeit & < 2000ms \\
AC-RC-02.2 & Rekursive Pfadberechnung & Tiefe $\geq$ 3, < 2000ms \\
AC-MC-01.3 & Material-Aggregation & < 500ms \\
\midrule
-- & \ac{TTI} aller Hauptseiten & < 3000ms \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Manuelle Evaluation} erfolgt für funktionale Akzeptanzkriterien ohne Performance-Vorgaben. Diese Kriterien beschreiben Funktionalitäten, deren Erfüllung durch Inspektion der implementierten Features feststellbar ist (z.B. \glqq Kanban-Board zeigt drei Spalten\grqq{}). Die Bewertung erfolgt durch den Entwickler anhand einer dreistufigen Skala: \textit{vollständig erfüllt}, \textit{teilweise erfüllt} oder \textit{nicht erfüllt}, jeweils mit Begründung.

Diese Differenzierung reduziert den Testaufwand auf die Kriterien, bei denen automatisierte Messung tatsächlichen Mehrwert liefert, ohne die Validierungsabdeckung zu kompromittieren.

\subsubsection{Testumgebung und -werkzeuge}

Die automatisierten Tests werden mit Playwright durchgeführt, einem 
modernen E2E-Testing-Framework von Microsoft. Playwright bietet 
gegenüber alternativen Frameworks wie Playwright mehrere Vorteile: 
native Unterstützung für parallele Testausführung, automatisches 
Warten auf Elemente (Auto-Waiting) sowie eine TypeScript-native 
API mit async/await-Syntax.

\begin{lstlisting}[caption={Performance-Messung in Playwright}, label={lst:playwright-performance}]
test('AC-QM-01.2: Filter-Latenz < 100ms', async ({ page }) => {
  await page.goto('/quests');
  
  const startTime = await page.evaluate(() => performance.now());
  await page.getByTestId('quest-search').fill(searchTerm);
  await page.getByTestId('quest-card')
    .filter({ hasText: searchTerm })
    .first()
    .waitFor();
  const endTime = await page.evaluate(() => performance.now());
  
  const duration = endTime - startTime;
  expect(duration).toBeLessThan(100);
});
\end{lstlisting}

Die Tests werden gegen die Produktivumgebung auf Vercel ausgeführt, um realistische Netzwerkbedingungen und Edge-Function-Latenzen abzubilden. Jeder Test wird mehrfach ausgeführt, um Varianz durch Netzwerkschwankungen zu reduzieren.

\subsubsection{Erfassungsschema für Akzeptanzkriterien}

Die Gesamtheit der Akzeptanzkriterien wird in einer strukturierten Matrix erfasst (Tabelle~\ref{tab:ac-erfassung-schema}). Für automatisiert getestete Kriterien werden die gemessenen Werte dokumentiert; für manuell evaluierte Kriterien erfolgt eine begründete Einordnung.

\begin{table}[htbp]
\centering
\caption{Erfassungsschema für Akzeptanzkriterien}
\label{tab:ac-erfassung-schema}
\begin{tabular}{lp{3cm}p{2cm}p{4cm}}
\toprule
\textbf{ID} & \textbf{Testmethode} & \textbf{Status} & \textbf{Evidenz/Begründung} \\
\midrule
AC-QM-01.1 & Manuell & $\checkmark$ / $\sim$ / $\times$ & [Beschreibung] \\
AC-QM-01.2 & E2E (Playwright) & $\checkmark$ / $\times$ & Gemessen: --ms \\
... & ... & ... & ... \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Qualitative Evaluation}
\label{sec:qual-eval-durchfuehrung}

Die qualitative Evaluation erhebt die subjektive Nutzererfahrung und bewertet, inwieweit die in Abschnitt~\ref{sec:problemstellung} identifizierten Probleme aus Nutzersicht gelöst wurden. Da die Anwendung zum Zeitpunkt der Evaluation nicht öffentlich verfügbar ist, entfallen nutzungsbasierte Metriken wie \ac{DAU}. Stattdessen erfolgt die Evaluation durch einen strukturierten Online-Fragebogen.

\subsubsection{Fragebogendesign}

Der Fragebogen wurde als Google Form implementiert und gliedert sich in drei Teile, die unterschiedliche Dimensionen der User Experience erfassen:

\textbf{Teil B: System Usability Scale (SUS)} umfasst die zehn standardisierten Items nach Brooke \cite{brooke1996sus}. Der \ac{SUS} ist ein etabliertes Instrument zur Messung der wahrgenommenen Usability und ermöglicht durch seinen standardisierten Score (0--100) den Vergleich mit Benchmark-Werten. Die Fragen werden auf einer fünfstufigen Likert-Skala beantwortet.

\textbf{Teil C: Problemlösungs-Bewertung} evaluiert direkt die in der Problemstellung identifizierten Kernprobleme sowie das im nachinein enstandene Recycling-Feature. Dieser Abschnitt ist in drei Dimensionen unterteilt:
\begin{enumerate}
    \item Quest-Übersicht und -Planung (Fragen C1--C3)
    \item Ressourcenmanagement (Fragen C4--C6)
    \item Recycling-Verständnis (Fragen C7--C9)
\end{enumerate}

Jede Dimension wird durch drei Fragen operationalisiert, die auf einer fünfstufigen Skala von \glqq überhaupt nicht gelöst\grqq{} (1) bis \glqq vollständig gelöst\grqq{} (5) beantwortet werden. Diese Struktur ermöglicht eine direkte Rückkopplung zur ursprünglichen Problemdefinition.

\textbf{Teil D: Feature-Bewertung} erfasst die Bewertung der zwölf implementierten Hauptfeatures auf einer fünfstufigen Skala. Zusätzlich steht die Option \glqq nicht genutzt\grqq{} zur Verfügung, um Features zu identifizieren, die von Nutzern möglicherweise nicht entdeckt wurden.

\subsubsection{Stichprobe und Durchführung}

Die Zielgruppe des Fragebogens sind Arc Raiders-Spieler, die die Anwendung vor dem Ausfüllen mindestens 30 Minuten genutzt haben. Diese Mindestnutzungsdauer stellt sicher, dass die Teilnehmer mit den Kernfeatures vertraut sind und eine fundierte Bewertung abgeben können.

Der Fragebogen wird asynchron über einen Zeitraum von zwei Wochen erhoben. Die Teilnehmer erhalten Zugang zur Anwendung sowie einen Link zum Fragebogen. Die Teilnahme ist freiwillig und anonym; es werden keine personenbezogenen Daten erfasst.

\subsubsection{Auswertungsmethodik}

Die quantitativen Fragebogendaten werden deskriptiv ausgewertet:

\begin{itemize}
    \item \textbf{SUS-Score:} Berechnung nach der standardisierten Formel (Summe der adjustierten Item-Scores multipliziert mit 2,5). Der resultierende Score wird anhand der Adjektivskala nach Bangor et al.~\cite{bangor2009determining} interpretiert.
    \item \textbf{Problemlösungs-Scores:} Berechnung des arithmetischen Mittels pro Problemdimension sowie über alle neun Items.
    \item \textbf{Feature-Scores:} Berechnung des arithmetischen Mittels pro Feature, Ranking nach Bewertung, Analyse der N/A-Raten zur Identifikation von Discovery-Problemen.
\end{itemize}

\subsection{Traceability und Ergebniszuordnung}
\label{sec:traceability-eval}

Die Evaluation schließt den Entwicklungszyklus: Problemstellung
→ User Stories → Akzeptanzkriterien → Implementierung → Test/Fragebogen
→ Ergebnisse. Diese Nachverfolgbarkeit ermöglicht in Kapitel 5 eine
direkte Gegenüberstellung von technischer Erfüllung (AC) und
wahrgenommener Problemlösung (UX-Score).

\begin{itemize}
    \item Erfüllungsgrad der Akzeptanzkriterien (quantitativ, entwicklerseitig)
    \item Problemlösungs-Bewertung (qualitativ, nutzerseitig)
\end{itemize}

Diese duale Perspektive ermöglicht eine differenzierte Bewertung: Ein Feature kann technisch alle Akzeptanzkriterien erfüllen, aber dennoch aus Nutzersicht das zugrundeliegende Problem nur teilweise lösen -- oder umgekehrt. Die kritische Reflexion dieser Diskrepanzen ist Gegenstand von Abschnitt~\ref{sec:kritische-reflexion}.

